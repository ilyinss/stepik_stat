---
title: "R part 3"
output:
  html_document:
    theme: prettydoc::hpstr
    highlight: tango
---

# Basic statistics // \|\|\|

## 1.3 Relationship linearity

Трансформация переменных - хорошее решение, если мы хотим добиться линейной взаимосвязи между переменными. Индикатором нелинейной взаимосвязи между переменными может служить `ненормальное`распределение остатков регрессии. При помощи трансформации Тьюки мы подбираем такой показатель степени, при котором `абсолютное значение корреляции` между переменными X и Y будет `максимальным`.

## 1.4 Logarythmics variables transformation

В модели $log(Y)=b_1*X+b_0$ коэффициент наклона означает: при единичном изменении переменной $X$, переменная $Y$ в среднем изменяется на $100*b_1$ процентов.

В модели $Y=b_1*log(X)+b_0$ коэффициент наклона означает: изменение на 1% по $X$ в среднем приводит к $0.01*b_1$ изменению по переменной Y.

В исследовании проверялась гипотеза о взаимосвязи мотивации студентов и денежного вознаграждения за проделанную работу. Исходные переменные оказались взаимосвязанными нелинейно, поэтому независимая переменная --- денежное вознаграждение --- была прологарифмирована (использовался натуральный логарифм). В результате была получена следующая модель:

$мотивация = 120*log(вознаграждение) + 3$

Укажите, *на сколько единиц в среднем* увеличивается мотивация при увеличении вознаграждения на 10 процентов. В ответе укажите целое число и не забывайте о правилах округления.

```{r}
y1 <- 120*log(100) + 3
y2 <- 120*log(110) + 3
print(y2-y1, digits = 0)
```

Трансформация Бокса --- Кокса (Box-Cox transformation) --- широко используемый метод трансформации данных. В контексте регрессии он обычно используется для трансформации зависимой переменной в случае, если у нас есть ненормальное распределение ошибок и/или нелинейность взаимосвязи, а также в случае гетероскедастичности.

Идея трансформации очень простая:\
$\large y_{new}=(y^{p}-1)/p, \ если \ p \neq 0$\
$\large y_{new} = log(y), \ если \ p = 0$

Параметр p подбирается по схожей идее: мы будем использовать то $p$, при котором качество модели максимально (обычно используется метод максимального правдоподобия).

Например, в случае множественной регрессии мы можем трансформировать зависимую переменную, чтобы добиться более высокого качества модели и выполнения требования к данным.

[О Боксе-Коксе на русском]('http://r-analytics.blogspot.ru/2015/07/blog-post_19.html')

[Box-Cox transformation in R]('https://www.youtube.com/watch?v=vGOpEpjz2Ks')

## 1.5 Heteroscedastic problem
