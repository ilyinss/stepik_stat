```{r}
library(ggplot2)
library(psych)
```

# 1. Preprocess

## 1.2 Variables

1.  Создайте переменную my_number и сохраните в нее число 42. Создайте переменную my_logical_var и сохраните в нее логическое значение TRUE.

```{r}
my_number <- 42
my_logical_var <- TRUE
```

2.  В уже созданной переменной var_1, в хранится целое число. Создайте новую переменную var_2, которая равняется var_1 умноженная на 10.

```{r}
var_2 <- var_1 * 10
```

3.  В уже созданных переменных number_1, number_2 и number_3, сохранены целые числа. Проверьте, действительно ли сумма первых двух чисел строго больше, чем третье число. Результат сравнения (TRUE или FALSE) сохраните в новую переменную с именем result.

```{r}
result <- (number_1+number_2)>number_3
```

4.  Создайте переменную the_best_vector, в которой хранятся числа от 1 до 5000 и затем числа от 7000 до 10000.

```{r}
the_best_vector <- c(1:5000,7000:10000)
```

5.  В уже созданной переменной my_numbers сохранен вектор из 20 целых чисел. Ваша задача создать новую переменную my_numbers_2, в которой будет сохранен 2, 5, 7, 9, 12, 16 и 20 элемент вектора my_numbers.

```{r}
my_numbers_2 <- my_numbers[c(2, 5, 7, 9, 12, 16, 20)]
```

6.  В уже созданной переменной my_vector хранится вектор из 20 целых чисел. Найдите сумму всех элементов вектора , которые больше 10. Сохраните сумму в переменную my_sum.

```{r}
my_sum <- sum(my_vector[my_vector > 10])
```

7.  В векторе my_vector отберите только те наблюдения, которые отклоняются от среднего меньше чем на одно стандартное отклонение. Сохраните эти наблюдения в новую переменную my_vector_2. При этом исходный вектор my_vector оставьте без изменений.

```{r}
my_vector <- c(21,18,21,19,25,20,17,17,18,22,17,18,18,19,19,27,21,20,24,17,15,
               24,24,29,19,14,21,17,19,18,18,20,21,21,19,19,17,21,13,17,13,23,
               15,23,24,16,17,25,24,22)
my_vector_2 <- my_vector[my_vector > mean(my_vector) - sd(my_vector) & my_vector < mean(my_vector) + sd(my_vector)]
my_vector_2
```

## 1.3 Dataframe

1.  В этой задаче поработаем со встроенными данными mtcars. В датафрэйме mtcars создайте новую колонку (переменную) под названием even_gear, в которой будут единицы, если значение переменной (gear) четное, и нули если количество нечетное.

```{r}

# 3 vars:
# mtcars$even_gear <- abs(1 - (mtcars$gear %% 2))
# mtcars$even_gear <- ifelse(mtcars$gear %% 2 == 0, 1, 0)
mtcars$even_gear <- (mtcars$gear+1) %% 2
mtcars$even_gear
```

2.  Продолжим нашу работу с данными mtcars. Теперь ваша задача создать переменную - вектор mpg_4 и сохранить в нее значения расхода топлива (mpg) для машин с четырьмя цилиндрами (cyl)

```{r}
mpg_4 <- mtcars$mpg[mtcars$cyl==4]
```

3.  Ваша задача создать новый dataframe под названием mini_mtcars, в котором будут сохранены только третья, седьмая, десятая, двенадцатая и последняя строчка датафрейма mtcars.

```{r}
mini_mtcars <- mtcars[c(3, 7, 10,12,nrow(mtcars)),]
```

## 1.4 Syntax

1.  Создайте новую числовую переменную new_var в данных mtcars, которая содержит единицы в строчках, если в машине не меньше четырёх карбюраторов (переменная "carb") или больше шести цилиндров (переменная "cyl"). В строчках, в которых условие не выполняется, должны стоять нули.

```{r}
mtcars$new_var <- ifelse(mtcars$carb >= 4 | mtcars$cyl > 6, 1, 0)
```

2.  В уже существующей переменной my_vector сохранен вектор из 50 чисел.

Решите задачу используя конструкцию:

    if () {  
    } else {  
    }  

Если среднее значение вектора my_vector больше 20, в переменную result сохраните "My mean is great", если среднее значение my_vector меньше или равно 20 то в переменную result сохраните строку "My mean is not so great".

```{r}
result <- ifelse (mean(my_vector)>20, "My mean is great", "My mean is not so great")
```

3.  В этой задаче от вас потребуется узнать некоторую информацию о типах данных в R самостоятельно! Встроенные в R данные AirPassengers - это новый для нас формат данных типа Time-Series. Изучите структуру этих данных, прежде чем начать решение задачи! Например напишите команды:

> ?AirPassengers \# справка о данных str(AirPassengers) \# структура данных

В встроенных в R данных AirPassengers хранится 144 значения (количество пассажиров в месяц) с 1949 по 1960 год. Данные Time-Series очень похожи на вектор по своей структуре, например мы можем обратиться к любому из 144 элементов используя уже знакомую нам индексацию AirPassengers[1] или AirPassengers[56].

Можно вообще перевести исходные данные в вектор при помощи команды as.vector(AirPassengers) и продолжить с ними работу как с вектором.

И так ваша задача создать переменную good_months и сохранить в нее число пассажиров только в тех месяцах, в которых это число больше, чем показатель в предыдущем месяце.

Важный момент! В R оператор : для создания последовательности имеет приоритет над арифметическими действиями. Таким образом, если у вас есть переменная i, равная 10, и вы хотите создать вектор от 1 до i - 1, воспользуйтесь скобками, чтобы указать последовательность действий.

```{r}
good_months <- AirPassengers[-1][AirPassengers[-1] > AirPassengers[-144]]
```

4.  Задачка для супер героев, повышенной сложности!

Для встроенных в R данных AirPassengers рассчитайте скользящее среднее с интервалом сглаживания равным 10. Напечатайте получившийся результат (первым значением в выводе должно быть среднее для элементов 1:10, во втором значении - среднее для элементов 2:11 и т.д., в последнем - среднее для элементов 135 :144) Все полученные значения средних сохраните в переменную moving_average.

Важный момент! В R оператор : для создания последовательности имеет приоритет над арифметическими действиями. Таким образом, если у вас есть переменная i, равная 10, и вы хотите создать вектор от 1 до i - 1, воспользуйтесь скобками, чтобы указать последовательность действий.

> i \<- 10 1 : i - 1 \# так мы создадим последовательность от 1 до 10, а потом вычтем единицу из каждого элемента\
> [1] 0 1 2 3 4 5 6 7 8 9

> 1 : (i - 1) \# а вот так мы создадим последовательность от 1 до i - 1, то есть от 1 до 9. [1] 1 2 3 4 5 6 7 8 9

Если вам потребуется создать вектор moving_average заранее, то есть несколько способов сделать это: 1. самый простой, но не очень правильный вариант - создать пустой вектор \>moving_average \<- c()

2.  можно сразу создать вектор определенной длины и определенного типа: \>moving_average \<- numeric(135)

Такой вариант является более предпочтительным. Почему? Узнаем во второй части курса!)

А для тем, кто уже выбрал путь воина и не хочет использовать цикл - советую познакомиться с функцией cumsum. Подсказка: если у нас есть два вектора одинаковой длинны, то если из одного вектора вычесть второй вектор, мы найдем разность для первых элементов векторов, затем для вторых и т.д.

```{r}
# vars

# 1

moving_average <- numeric(135)
for(i in 1:135) {
  moving_average[i] <- mean(AirPassengers[c(i:(i+9))])
}

# 2 - R style

n <- 10    
d <- AirPassengers    
cx <- c(0, cumsum(d))    
moving_average <- (cx[(n + 1):length(cx)] - cx[1:(length(cx) - n)]) / n
```

## 1.5 Described statistics

1.  Вновь вернемся к данным mtcars. Рассчитайте среднее значение времени разгона (qsec) для автомобилей, число цилиндров (cyl) у которых не равняется 3 и показатель количества миль на галлон топлива (mpg) больше 20. Получившийся результат (среднее значение) сохраните в переменную result.

```{r}
result <- mean(mtcars$qsec[mtcars$cyl != 3 & mtcars$mpg > 20])
```

2.  При помощи функции aggregate рассчитайте стандартное отклонение переменной hp (лошадиные силы) и переменной disp (вместимости двигателя) у машин с автоматической и ручной коробкой передач.

Полученные результаты (результаты выполнения функции aggregate) сохраните в переменную descriptions_stat.

```{r}
descriptions_stat <- aggregate(cbind(hp, disp) ~ am, mtcars, sd)
```

3.  Воспользуемся встроенными данными airquality. В новую переменную сохраните subset исходных данных, оставив наблюдения только для месяцев 7, 8 и 9.

При помощи функции aggregate рассчитайте количество непропущенных наблюдений по переменной Ozone в 7, 8 и 9 месяце. Для определения количества наблюдений используйте функцию length().

Результат выполнения функции aggregate сохраните в переменную result.

Подсказки:

1.  Не забудьте сделать subset, чтобы отобрать наблюдения только по нужным месяцам, вам может пригодиться следующая конструкция:

> x \<- 5 x %in% c(3, 4, 5) [1] TRUE

2.  Для подсчета числа непропущенных наблюдений воспользуйтесь записью с помощью формулы, при которой пропущенные значения не учитываются: \> aggregate(y \~ x + z , data, FUN)

```{r}
# vers

# 1
# df <- subset(airquality, Month%in%c(7,8,9))
# result <- aggregate(Ozone ~ Month,df,length)

# 2
descriptions_stat <- aggregate(cbind(hp,disp) ~ am, mtcars, sd)
```

3.  Примените функцию describeBy к количественным переменным данных airquality, группируя наблюдения по переменной Month. Чему равен коэффициент асимметрии (skew) переменной Wind в восьмом месяце?

```{r}
# v1 
# describeBy(airquality, airquality$Month == 8)[['TRUE']]['Wind','skew']

# v2
describeBy(airquality$Wind, airquality$Month == 8)$'TRUE'['skew']
```

4.  Обратимся к встроенным данным iris. Соотнесите значения стандартного отклонения переменных.

```{r}
describe(iris)['sd']
```

5.  В данных iris расположите по убыванию значения медиан количественных переменных в группе virginica.

```{r}
describeBy(iris, group = iris$Species)$virginica['median']
```

6.  В переменной my_vector сохранен вектор с пропущенными значениями. Вам нужно создать новый вектор fixed_vector, в котором все пропущенные значения вектора my_vector будут заменены на среднее значение по имеющимся наблюдениям.

При этом исходный вектор оставьте без изменений!

Напоминаю, переменная my_vector уже создана, сразу начинайте работать с ней. Перед тем, как сдавать решение, вы можете потренироваться на различных примерах. Ниже небольшой код, который может создать случайный вектор (выборка из нормального распределения) с пропущенными значениями. \> my_vector \<- rnorm(30) \> my_vector[sample(1:30, 10)] \<- NA \# на десять случайных позиций поместим NA

```{r}
fixed_vector <- replace(my_vector, is.na(my_vector), mean(my_vector, na.rm = T))
```

## 1.6 Described statistics // Plots

1.  При помощи функции ggplot() или boxplot() постройте график boxplot, используя встроенные в R данные airquality. По оси x отложите номер месяца, по оси y --- значения переменной Ozone.

На графике boxplot отдельными точками отображаются наблюдения, отклоняющиеся от 1 или 3 квартиля больше чем на полтора межквартильных размаха. Сколько таких наблюдений присутствует в сентябре (месяц №9)?

Обратите внимание, что для корректного отображения графика ggplot ожидает факторную переменную по оси x.

```{r}
# v1
# boxplot(Ozone ~ Month, airquality)

# v2
ggplot(airquality, aes(x = Month, y = Ozone, group = Month)) + geom_boxplot()
```

2.  Используем знакомые нам данные mtcars.

Нужно построить scatterplot с помощью ggplot из ggplot2, по оси x которого будет mpg, по оси y - disp, а цветом отобразить переменную (hp).

Полученный график нужно сохранить в переменную plot1. Таким образом в ответе должен быть скрипт:

> plot1 \<- ggplot(data, aes())+ geom\_\*\*\*\*()

```{r}
plot1 <- ggplot(mtcars, aes(x = mpg, y = disp, col = hp))+
  geom_point()
```

3.  Укажите, при помощи какого варианта кода мы можем построить следующий график по данным iris: Гистограмма распределения переменной Sepal.Length, в которой цвет заполнения столбцов гистограммы зависит от значения переменной Species.

> ans:\
> ggplot(iris, aes(Sepal.Length)) + geom_histogram(aes(fill = Species))\
> ggplot(iris, aes(Sepal.Length, fill = Species)) + geom_histogram()

4.  Студент Ярослав очень любит строить графики в R. Основываясь на данных iris он хочет построить следующий график:

Scatterplot (диаграмма рассеивания), где по оси X будет отложена переменная Sepal.Length, по оси Y переменная Sepal.Width. За цвет точек будет отвечать переменная Species, а за размер точек переменная Petal.Length.

Ярослав написал следующую команду

> ggplot(aes(Sepal.Length, Sepal.Width, col = Species)) +\
> geom_point(iris, size = Petal.Length)

Однако построить желаемый график не удается! Укажите, какие ошибки совершил Ярослав и попробуйте построить данный график самостоятельно.

> ans:\
> Первым аргументом функции ggplot() должны быть данные iris.\
> Переменная, отвечающая за размер точек должна быть указана внутри функции aes()\

```{r}
ggplot(iris, aes(Sepal.Length, Sepal.Width, col = Species))+
  geom_point(aes(size = Petal.Length))
```

# 2. Statistics in R // Part 1

## 2.1 Nominative data analyze

1.  К частям таблицы можно обращаться так же, как и к матрицам.

HairEyeColor - таблица с данными, встроенными в R. Посмотрите на неё в R. Команда dimnames(HairEyeColor) позволит нам посмотреть, какие измерения есть в этой таблице и как они называются. Например, чтобы обратиться к части таблицы, в которой хранятся данные только о мужчинах, нам нужно выполнить следующую команду: \> HairEyeColor[ , ,'Male']

Ваша задача в переменную red_men сохранить долю рыжеволосых (Red) от общего числа голубоглазых мужчин.

Обратите внимание, что нужны не проценты, а просто доля, то есть десятичная дробь (например, не 10%, а 0.1).

```{r}
red_men <- prop.table(HairEyeColor[ , ,'Male'],2)['Red', 'Blue']
```

2.  Напишите число зеленоглазых женщин в наборе данных HairEyeColor

```{r}
sum(HairEyeColor[,'Green','Female'])
```

3.  Постройте столбчатую диаграмму распределения цвета глаз по цвету волос только у женщин из таблицы HairEyeColor. По оси X должен идти цвет волос, цвет столбиков должен отражать цвет глаз. По оси Y - количество наблюдений.

Чтобы построить столбчатую диаграмму в ggplot, вам нужно подключить нужный пакет, затем преобразовать таблицу HairEyeColor в data frame:

> mydata \<- as.data.frame(HairEyeColor)

Постройте график на основе предложенного кода, сохранив его в переменную obj. Укажите, чему равен аргумент data, что должно находиться в aes(). Изучите справку по geom_bar(), чтобы узнать, чему должен равняться аргумент position для отображения цвета глаз в виде соседних столбиков, также вам может быть полезна эта памятка. Там же вы найдёте ответ на вопрос, за что отвечает аргумент stat. С помощью scale_fill_manual мы говорим графику, что мы хотим, чтобы он использовал указанные нами цвета. Дополните предложенный код:

`library("ggplot2")`\
`mydata <- as.data.frame(HairEyeColor)`\
`obj <- ggplot(data = , aes(x = , y = Freq)) + geom_bar(stat="identity", position = ) + scale_fill_manual(values=c("Brown", "Blue", "Darkgrey", "Darkgreen"))`

У себя на компьютере вы можете визуализировать полученный график, исполнив `obj`. В случае, если все сделано правильно, он будет выглядеть так (обратите внимание на название осей и легенды):

Прежде чем отправить код на проверку, выполните его на своем компьютере, чтобы избежать лишних ошибок. При ошибке, обратите внимание на содержание feedback.

```{r}
mydata <- as.data.frame(HairEyeColor)
obj <- ggplot(subset(mydata, Sex %in% c('Female')), aes(x = Hair, y = Freq, fill = Eye))+
  geom_bar(stat = "identity", position = "dodge")+
  scale_fill_manual(values=c("Brown", "Blue", "Darkgrey", "Darkgreen"))
```

4.  На основе таблицы HairEyeColor создайте ещё одну таблицу, в которой хранится информация о распределении цвета глаз у женщин-шатенок (Hair = 'Brown'). Проведите тест равномерности распределения цвета глаз у шатенок и выведите значение хи-квадрата для этого теста.

```{r}
chisq.test(HairEyeColor['Brown',,'Female'])
```

5.  Воспользуемся данными diamonds из библиотеки ggplot2. При помощи критерия Хи - квадрат проверьте гипотезу о взаимосвязи качества огранки бриллианта (сut) и его цвета (color). В переменную main_stat сохраните значение статистики критерия Хи - квадрат. Обратите внимание, main_stat должен быть вектором из одного элемента, а не списком (листом).

Данные diamonds уже доступны для работы!

```{r}
t1 <- table(diamonds$cut, diamonds$color)
main_stat <- chisq.test(t1)$statistic
```

6.  Опять воспользуемся данными diamonds из библиотеки ggplot2. При помощи критерия Хи - квадрат проверьте гипотезу о взаимосвязи цены (price) и каратов (carat) бриллиантов. Для этого сначала нужно перевести эти количественные переменные в формат пригодный для Хи - квадрат. Создайте две новые переменные в данных diamonds:

factor_price - где будет 1, если значение цены больше либо равно чем среднее, и 0, если значение цены ниже среднего цены по выборке.

factor_carat - где будет 1, если число карат больше либо равно чем среднее, и 0, если ниже среднего числа карат по выборке.

Важный момент - на больших данных цикл for() работает довольно медленно, постарайтесь решить эту задачу без его использования!

Используя эти шкалы при помощи Хи - квадрат проверьте исходную гипотезу. Сохраните в переменную main_stat значение критерия Хи - квадрат.

Пример перевода количественной шкалы в номинативную:

> x \<- (1, 2, 3, 5, 6, 7) \# mean(x) = 4 factor_x \<- (0, 0, 0, 1, 1, 1)

```{r}
diamonds$factor_price <- ifelse(diamonds$price >= mean(diamonds$price), 1, 0)
diamonds$factor_carat <- ifelse(diamonds$carat >= mean(diamonds$carat), 1, 0)
main_stat <- chisq.test(diamonds$factor_price, diamonds$factor_carat)$statistic
```

7.  При помощи точного критерия Фишера проверьте гипотезу о взаимосвязи типа коробки передач (am) и типа двигателя (vs) в данных mtcars. Результат выполнения критерия сохраните в переменную.Получившийся p - уровень значимости сохраните в переменную fisher_test.

```{r}
fisher_test <- fisher.test(mtcars$am, mtcars$vs)$p.value
```

## 2.2 2 groups compare

Воспользуемся еще одним встроенным набором данных в R - ToothGrowth. Данные позволяют исследовать рост зубов у морских свинок в зависимости от дозировки витамина C и типа потребляемых продуктов.

Сравните среднее значение длины зубов свинок, которые потребляли апельсиновый сок (OJ) с дозировкой 0.5 миллиграмм, со средним значением длины зубов свинок, которые потребляли аскорбиновую кислоту (VC) с дозировкой 2 миллиграмма.

Значение t - критерия сохраните в переменную t_stat.

```{r}
guinea_pig1 <- subset(ToothGrowth, supp == 'OJ' & dose==0.5)$len
guinea_pig2 <- subset(ToothGrowth, supp == 'VC' & dose==2)$len
t_stat <- t.test(guinea_pig1, guinea_pig2)$statistic

# good solution:
# correct_data <- subset(ToothGrowth, supp=='OJ' & dose==0.5 | supp=='VC' & dose==2)    
# t_stat <- t.test(len ~ supp, correct_data)$statistic

```

Скачайте данные, посвященные влиянию различного типа лечения на показатель артериального давления.

> <https://stepic.org/media/attachments/lesson/11504/lekarstva.csv>

По всем испытуемым сравните показатель давления до начала лечения (Pressure_before) с показателем давления после лечения (Pressure_after) при помощи t - критерия для зависимых выборок. В поле для ответа укажите значение t - критерия. (В качестве десятичного разделителя используйте запятую, например: 123,54)

```{r}
df <- read.csv('https://stepic.org/media/attachments/lesson/11504/lekarstva.csv')
t_test <- t.test(df$Pressure_before, df$Pressure_after, paired = T)
t_test$statistic
```

В этом задании нужно проверить гипотезу о равенстве средних двух выборок, загрузив набор данных (нажмите начать решать задание) и выполнив все необходимые операции на вашем компьютере. В скачанных данных вы найдете две переменные: количественную переменную, и номинативную переменную с двумя градациями (которая разделяет наблюдения на две группы).

Для того чтобы без труда прочитать скачанные данные воспользуйтесь функцией: read.table("dataset_11504_11.txt") \> \# разумеется, у вас может быть другое название файла \> \# также убедитесь, что файл находится в рабочей директории \> \# или укажите полный путь к файлу

Сначала с помощью теста Бартлетта проверьте гомогенность дисперсий двух выборок. В случае, если дисперсии значимо не отличаются (с уровнем 0.05), примените тест Стьюдента, иначе - непараметрический тест (Манна-Уитни). В поле для ответа введите получившийся p-value, с точностью четыре знака после запятой. Обратите внимание, что по умолчанию в t.test стоит var.equal = FALSE, так как мы будем применять его только в случае гомогенности дисперсий, измените значение этого параметра на var.equal = TRUE.

Каждый раз вы будете скачивать новый набор данных.

Важно - в этом ответе используйте точку как десятичный разделитель!

Если p - value сильно меньше 0.05, например, 1.01e-07, в поле для ответа можете ввести 0

```{r}
df <- read.table('dataset_11504_15.txt', header=FALSE)
b_test <- bartlett.test(V1 ~ V2, df)
if (b_test$p.value>=0.05){
  print(round(x=t.test(V1 ~ V2, df, var.equal = T)$p.value, digits = 4))
}else{
  print(round(x = wilcox.test(V1 ~ V2, df)$p.value, digits = 4))
}
```

В данных сохранены две количественные переменные, проверьте гипотезу о равенстве средних этих переменных при помощи t- теста для независимых выборок.

Если обнаружены значимые различия (p\< 0.05), то введите через пробел три числа: среднее значение первой переменной, среднее значение второй переменной, p - уровень значимости. Например:

> 22.45 12.56 0.04

Если значимые различия не обнаружены, то в поле для ответа введите:

"The difference is not significant"

В этой задаче оставьте var.equal = FALSE

```{r}
df <- read.table('dataset_11504_16.txt', header=FALSE)
t_test <- t.test(df$V1, df$V2, var.equal = F)
if (t_test$p.value<0.05){
  print(mean(df$V1), mean(df$V2), t_test$p.value)
}else{
  print('The difference is not significant')
}
```

## 2.3 Use dispersion analysis

Воспользуемся встроенными данными npk, иллюстрирующими влияние применения различных удобрений на урожайность гороха (yield). Нашей задачей будет выяснить, существенно ли одновременное применение азота (фактор N) и фосфата (фактор P). Примените дисперсионный анализ, где будет проверяться влияние фактора применения азота (N), влияние фактора применения фосфата (P) и их взаимодействие. В ответе укажите p-value для взаимодействия факторов N и P.

```{r}
fit <- aov(yield ~ N*P, data=npk)
summary(fit)
```

Теперь проведите трехфакторный дисперсионный анализ, где зависимая переменная - это урожайность (yield), а три фактора - типы удобрений (N, P, K). После проведения данного анализа вы получите три значения p - уровня значимости (о значимости каждого из факторов).

```{r}
fit <- aov(yield ~ N+P+K, data=npk)
summary(fit)
```

Проведите однофакторный дисперсионный анализ на встроенных данных iris. Зависимая переменная - ширина чашелистика (Sepal.Width), независимая переменная - вид (Species). Затем проведите попарные сравнения видов. Какие виды статистически значимо различаются по ширине чашелистика (p \< 0.05)?

```{r}
fit <- aov(Sepal.Width ~ Species, data=iris)
TukeyHSD(fit)
```

В этой задаче вам дан набор данных, в котором представлена информация о температуре нескольких пациентов, которые лечатся разными таблетками и у разных врачей.

Проведите однофакторный дисперсионный анализ с повторными измерениями: влияние типа таблетки (pill) на температуру (temperature) с учётом испытуемого (patient). Каково p-value для влияния типа таблеток на температуру? \> Данные: <https://stepic.org/media/attachments/lesson/11505/Pillulkin.csv>

```{r}
df <- read.csv('https://stepic.org/media/attachments/lesson/11505/Pillulkin.csv')
# head(df)
df$patient <- as.factor(df$patient)
fit <- aov(temperature ~ pill + Error(patient/pill), data = df)
s_fit <- summary(fit)
s_fit <- s_fit$`Error: patient:pill`
s_fit
```

Теперь вашей задачей будет провести двухфакторный дисперсионный анализ с повторными измерениями: влияние факторов doctor, влияние фактора pill и их взаимодействие на temperature. Учтите обе внутригрупповые переменные: и тот факт, что один и тот же больной принимает разные таблетки, и тот факт, что один и тот же больной лечится у разных врачей! Каково F-значение для взаимодействия факторов доктора (doctor) и типа таблеток (pill)?

Данные: <https://stepic.org/media/attachments/lesson/11505/Pillulkin.csv>

```{r}
fit <- aov(temperature ~ doctor*pill + Error(patient/pill*doctor), data = df)
s_fit <- summary(fit)
s_fit
```

Вспомните графики из лекций и дополните шаблон графика в поле для ответа так (не добавляя еще один geom) , чтобы объединить линиями точки, принадлежащие разным уровням фактора supp. Не забудьте подключить нужный для построение графика пакет. Пожалуйста, сохраните график в переменную obj.

```{r}
pd = position_dodge(0.2)
ggplot(ToothGrowth, aes(x = as.factor(dose), y = len, col = supp, group = supp))+
  stat_summary(fun.data = mean_cl_boot, geom = 'errorbar', width = 0.1, position = pd)+
  stat_summary(fun.data = mean_cl_boot, geom = 'point', size = 3, position = pd)+
  stat_summary(fun.data = mean_cl_boot, geom = 'line', position = pd)
```

## 2.4 Make custom functions

Напишите функцию, которая выводит номера позиций пропущенных наблюдений в векторе.

На вход функция получает числовой вектор с пропущенными значениями. Функция возвращает новый вектор с номерами позиций пропущенных значений.

Подсказка: чтобы проверить является ли наблюдение NA, воспользуйтесь функцией is.na(), кстати, функция векторизирована, и аргументом может служить вектор произвольной длинны. Запись x == NA ни к чему осмысленному не приведет. Т.к. если x это NA, то команда x == NA также вернет NA, а не TRUE!

> my_vector \<- c(1, 2, 3, NA, NA) NA.position(my_vector) [1] 4 5

```{r}
my_vector <- c(1, 2, 3, NA, NA)

# first
NA.position <- function(x){
  ans <- c()
  for (i in 1:length(x)){
    if (is.na(x[i]) == T){
      ans <- c(ans, i)
    }
  } 
  return(ans)
  }

print(NA.position(my_vector))


# second

NA.position <- function(x){    
  which(is.na(x))}

print(NA.position(my_vector))

```

Напишите функцию NA.counter для подсчета пропущенных значений в векторе.

На вход функция NA.counter должна принимать один аргумент - числовой вектор. Функция должна возвращать количество пропущенных значений.

> my_vector \<- c(1, 2, 3, NA, NA) NA.counter(my_vector) [1] 2

```{r}
# first
NA.counter <- function(x){    
  length(which(is.na(x)))}

print(NA.counter(my_vector))

# second
NA.counter <- function(x){    
  sum(is.na(x))}

NA.counter(my_vector)

```

Напишите функцию filtered.sum, которая на вход получает вектор с пропущенными, положительными и отрицательными значениями и возвращает сумму положительных элементов вектора.

> filtered.sum(c(1, -2, 3, NA, NA)) [1] 4

```{r}
filtered.sum <- function(x){
  return(sum(x[x>0], na.rm = T))
}

filtered.sum(my_vector)
```

Задача для героев!

Напишите функцию outliers.rm, которая находит и удаляет выбросы. Для обнаружения выбросов воспользуемся самым простым способом, с которым вы не раз встречались, используя график Box plot.

Выбросами будем считать те наблюдения, которые отклоняются от 1 или 3 квартиля больше чем на 1,5 \* IQR, где IQR - межквартильный размах.

На вход функция получает числовой вектор x. Функция должна возвращать модифицированный вектор x с удаленными выбросами.

Ссылка на видео с объяснением, как на графике box-plot отображаются выбросы: <https://stepik.org/lesson/9294/step/4?course=%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D1%8B-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B8&unit=1827>

Полезные функции:

IQR(x) - рассчитывает межквартильный размах вектора x

quantile(x, probs = c(0.25, 0.75)) - рассчитывает первый и третий квартиль вектора x

```{r}
my_vector <- c(1, 1, 2, 3, 10,15,30, 7, 105)

# first

outliers.rm <- function(x){
  ans <- c()
  q1 <- quantile(x,probs=c(0.75))
  q3 <- quantile(x,probs=c(0.25))
  wide_IQR <- 1.5*IQR(x)
  for(i in 1:length(x)){
    if (x[i]<(q1+wide_IQR) & x[i]>(q3-wide_IQR)) {
      ans <- append(ans, x[i])
    }
  }
  return(ans)
}

print(outliers.rm(my_vector))

# second

outliers.rm <- function(x){    
  q <- quantile(x, 0.25) + quantile(x, 0.75)    
  return(x[abs(x - q/2) <= 2*IQR(x)])
  }
```

```{r}
my_vector <- c(1, 2, 3, 10, 7)
iqr.1.5 <- IQR(my_vector)*1.5
iqr.1.5
# quant_1 <- unname(quantile(my_vector, probs = c(0.25)))
# quant_3 <- unname(quantile(my_vector, probs = c(0.75)))
# quant_3 - quant_1
```

# 3. Statistics in R // Part 2

## 3.1 Corr and simple linear regression

Напишите функцию corr.calc, которая на вход получает data.frame с двумя количественными переменными, рассчитывает коэффициент корреляции Пирсона и возвращает вектор из двух значений: коэффициент корреляции и p - уровень значимости.

Пример работы функции:

> corr.calc( mtcars[, c(1,5)] ) \# на вход подаем данные mtcars только с переменными mpg и drat [1] 0.6811719078 0.0000177624

> corr.calc( iris[,1:2] ) \# на вход подаем данные iris только с переменными Sepal.Length и Sepal.Width [1] -0.1175698 0.1518983

При написании функции обратите внимание, что названия переменных входящего dataframe могут быть произвольными. Пишите функцию с учетом, что она должна работать на любом dataframe с двумя количественными переменными как в примере выше.

> Не забудьте подгрузить библиотеку library(psych), если хотите использовать ее при решении этой задачи

```{r}
corr.calc <- function(x){
  fit <- cor.test(~x[,1]+x[,2],x,method = 'pearson')
  return(c(fit$estimate,fit$p.value))
}
corr.calc(mtcars)
```

Напишите функцию `filtered.cor` которая на вход получает `data.frame` с произвольным количеством переменных (как количественными, так и любых других типов), рассчитывает коэффициенты корреляции Пирсона между всеми парами количественных переменных и возвращает наибольшее по модулю значение коэффициента корреляции. (То есть функция может вернуть -0.9, если это наибольшая по модулю корреляция).

Гарантируется наличие в `data.frame` хотя бы двух количественных переменных.

Обратите внимание: при проверке вашей функции на вход будут подаваться данные с различными именами колонок. Ваша функция должна корректно работать независимо от имен переменных. Перед тем, как сдавать решение, убедитесь, что ваша функция работает корректно на разных данных, с разными именами колонок.

Если вы хотите использовать функцию `corr.test` не забудьте загрузить библиотекy `psych`.

Данные для тренировки:

<https://stepic.org/media/attachments/lesson/11504/step6.csv>

`step6 <- read.table("step6.csv", header=TRUE, sep=',' )`

`filtered.cor(step6)`

`[1] 0.235997`

> `filtered.cor(my_df)` \# вымышленные данные, где максимальная по модулю корреляция отрицательна

> [1] -0.9

> `filtered.cor(iris)`

> [1] 0.9628654

`iris$Petal.Length <- -iris$Petal.Length` \# сделаем отрицательной максимальную по модулю корреляцию filtered.cor(iris)

> [1] - 0.9628654

1.  мы подробнее поговорим о функциях семейства `apply` в следующем курсе - `Advanced R`, но вы можете изучить справку о `apply` и `sapply`. Для решения данной задачи, эти функции могут пригодиться.\
2.  обратите внимание на функцию `which.max()`\
3.  обратите внимание на конструкцию `diag(matrix) <- n`\
4.  если вы получаете ошибку, 'x' must be a numeric vector, значит в данных остались не только количественные переменные.

```{r}
df <- read.csv(
  'https://stepic.org/media/attachments/lesson/11504/step6.csv', 
  header=TRUE, 
  sep=',' 
  )

filtered.cor <- function(x){
  res <- x[, sapply(x, is.numeric)]
  res <- cor(res, method = "pearson", use = "complete.obs")
  diag(res) <- 0    
  res[which.max(abs(res))]
} 

filtered.cor(df)
```

Напишите функцию `smart_cor`, которая получает на вход `dataframe` с двумя количественными переменными. Проверьте с помощью теста Шапиро-Уилка, что данные в обеих переменных принадлежат нормальному распределению.

Если хотя бы в одном векторе распределение переменной отличается от нормального (`p - value` меньше 0.05), то функция должна возвращать коэффициент корреляции Спирмена. (Числовой вектор из одного элемента).

Если в обоих векторах распределение переменных от нормального значимо не отличается, то функция должна возвращать коэффициент корреляции Пирсона.

`test_data  <- read.csv("https://stepik.org/media/attachments/course/129/test_data.csv")` `smart_cor(test_data)` \> [1] -0.1031003

```{r}
test_data <- read.csv('https://stepik.org/media/attachments/course/129/test_data.csv')

smart_cor <- function(x){
  re_df <- x[, sapply(x, is.numeric)]
  x1 <- shapiro.test(re_df[[1]])$p.value
  x2 <- shapiro.test(re_df[[2]])$p.value
  
  if ((x1<0.05) | (x2<0.05)) {
    res <- cor.test(~ re_df[[1]]+re_df[[2]], re_df, method = "spearman")
  } else {
    res <- cor.test(~ re_df[[1]]+re_df[[2]], re_df, method = "pearson")
  }
  return(res$estimate)
}

smart_cor(test_data)

# other solution

smart_cor <- function(x){    
if (shapiro.test(x[[1]])$p < 0.05 | shapiro.test(x[[2]])$p < 0.05) {    
return(cor.test(x[[1]], x[[2]], method = 'spearman')$estimate)    
} else {    
return(cor.test(x[[1]], x[[2]], method = 'pearson')$estimate)}}


```

Скачайте набор данных - `dataframe` с двумя количественными переменными (вспомните при необходимости, как задавать разделитель и другие параметры функции `read.table`), постройте линейную регрессию, где - первая переменная - зависимая, вторая - независимая. В ответ укажите значения регрессионных коэффициентов сначала `intercept` затем `slope`.

Десятичный разделитель - точка. В поле для ответа введите два числа, не округляйте значения, например;

> 12.434 6.2557

```{r}
df <- read.table('dataset_11508_12.txt')
fit  <- lm(V1 ~ V2, df)

fit$coefficients
```

Воспользуемся уже знакомыми данными `diamonds` из библиотеки `ggplot2`. Только для бриллиантов класса `Ideal` (переменная `cut`) c числом карат равным 0.46 (переменная `carat`) постройте линейную регрессию, где в качестве зависимой переменной выступает `price`, в качестве предиктора - переменная `depth`. Сохраните коэффициенты регрессии в переменную `fit_coef`. Памятка:

`fit <- lm(mpg ~ disp + wt, mtcars)`\
`fit$coefficients # коэффициенты модели`

Это задание нужно решить, не используя цикл for().

```{r}
df <- subset(diamonds, cut == "Ideal" & carat == 0.46)
fit <- lm(price ~ depth, df)
fit_coef <- fit$coefficients
fit_coef
```

Напишите функцию `regr.calc`, которая на вход получает `dataframe` c двумя переменными.

Если две переменные значимо коррелируют (p - уровень значимости для коэффициента корреляции Пирсона меньше 0.05), то функция строит регрессионную модель, где первая переменная - зависимая, вторая - независимая. Затем создает в `dataframe` новую переменную с назанием `fit`, где сохраняет предсказанные моделью значения зависимой переменной. В результате функция должна возвращать исходный `dataframe` с добавленной новой переменной `fit`.

Если две переменные значимо не коррелируют, то функция возвращает строчку "There is no sense in prediction"

Примеры работы функции:

`my_df = iris[,1:2] # на вход подаем данные iris только с переменными Sepal.Length и Sepal.Width`\
`regr.calc(iris[,1:2]) # переменные значимо не коррелируют`

> [1] "There is no sense in prediction"

> my_df = iris[,c(1,4)] \# на вход подаем данные iris только с переменными Sepal.Length и Petal.Width regr.calc(my_df) \# переменные значимо коррелируют

`Sepal.Length Petal.Width fit`

`1            5.1       0.2   4.955345`\
`2            4.9       0.2   4.955345`\
`3            4.7       0.2   4.955345`\
`.            .         .     .`\
`.            .         .     .`

Обратите внимание, при проверке вашей функции на вход будут подаваться данные с различными именами колонок. Ваша функция должна корректно работать в независимости от имен переменных.

Перед тем как сдавать решение убедитесь, что ваша функция работает корректно на разных данных, с разными именами колонок.

```{r}
# my_df <- iris[,1:2]
my_df <- iris[,c(1,4)]
regr.calc <- function(x){
  if (cor.test(x[[1]], x[[2]], method = 'pearson')$p.value<0.05){
    x$fit <- lm(x[,1] ~ x[,2], x)$fitted.values
    return(x)
  }
  else{
    return('There is no sense in prediction')
  }
}
regr.calc(my_df)
```

Постройте `scatterplot` по данным `iris`, сохранив его в переменную `my_plot` : Ось X - переменная `Sepal.Width` Ось Y - переменная `Petal.Width` Цвет точек - переменная `Species` Также добавьте линейное сглаживание для каждой группы наблюдений по переменной `Species`.

```{r}
my_plot <- ggplot(iris, aes(Sepal.Width, Petal.Width, col=Species))+
  geom_point(size = 3)+
  geom_smooth(method = "lm")
  
  

my_plot
```

## 3.2 Multiple linear regression

Напишите функцию fill_na, которая принимает на вход данные с тремя переменными:

x_1 - числовой вектор\
x_2 - числовой вектор\
y - числовой вектор с пропущенными значениями.

Теперь --- самое интересное. На первом этапе, используя только наблюдения, в которых нет пропущенных значений, мы построим регрессионную модель (без взаимодействий), где y --- зависимая переменная, x_1 и x_2 --- независимые переменные. Затем, используя построенную модель, мы заполним пропущенные значения предсказаниями модели.

Функция должна возвращать dataframe c новой переменной y_full. Сохраните в нее переменную y, в которой пропущенные значения заполнены предсказанными значениями построенной модели.

```{r}
?subset
```

```{r}
test_data <- read.csv("https://stepic.org/media/attachments/course/129/fill_na_test.csv")
```

```{r}
fill_na <- function(x){
  model <- lm(x[,3]~x[,1]+x[,2], data=x, na.action = "na.exclude")
  x$y_full <- ifelse(is.na(x[,3]), predict(model, x), x[,3])
  return(x)
}
fill_na(test_data)
```

В переменной df сохранен subset данных mtcars только с переменными "wt", "mpg", "disp", "drat", "hp". Воспользуйтесь множественным регрессионным анализом, чтобы предсказать вес машины (переменная "wt"). Выберите такую комбинацию независимых переменных (из "mpg", "disp", "drat", "hp"), чтобы значение R\^2 adjusted было наибольшим. Взаимодействия факторов учитывать не надо.

Выполните все операции по сравнению моделей на вашем компьютере. В поле для ответа сохраните в переменную model регрессионную модель с оптимальной комбинацией предикторов!

```{r}
df <- subset(mtcars, select = c("wt", "mpg", "disp", "drat", "hp"))
model <- lm(wt ~ mpg + disp + drat + hp, df)
d <- step(model, direction = 'backward', SCALE=1)
```

Воспользуйтесь встроенным датасетом attitude, чтобы предсказать рейтинг (rating) по переменным complaints и critical. Каково t-значение для взаимодействия двух факторов?

Разделителем целой и дробной части в ответе должна быть запятая!

```{r}
mod <- summary(lm(rating~complaints*critical, data=attitude))
mod$coefficients[4,3]
```

Визуализируйте взаимодействие переменных wt и am, дополнив код, приведённый в задании: Ось x - переменная wt Ось y - переменная mpg Цвет регрессионных прямых - переменная am

```{r}
mtcars$am <- factor(mtcars$am)

my_plot <- ggplot(mtcars, aes(x = wt, y = mpg, col = am))+
  geom_smooth(method = "lm")
my_plot
```

## 3.3 Multiple linear regression // Extract models

Сейчас мы поработаем со встроенным датасетом `attitude`. Рассмотрим две модели

`model_full <- lm(rating ~ ., data = attitude)`

`model_null <- lm(rating ~ 1, data = attitude)`

`model_full` - модель, которая предсказывает значение переменной рейтинг (`rating`) в зависимости от всех остальных переменных в данном датасете.

`model_null` - модель, в которой нет ни одного предиктора, а есть только `intercept`. Значение `intercept` - это просто среднее значение зависимой переменной. Соответственно, модель предоставляет нам информацию только о том, отличается ли это среднее от нуля.

Как говорилось в лекции, функция `step` позволяет нам подобрать модель с оптимальным количеством предикторов. С помощью аргумента `scope` мы можем задать пространство моделей с разным числом предикторов, в котором будет происходить поиск оптимального набора предикторов. Самый простой путь - задать границы возможных моделей с помощью нулевой и полной моделей.

`scope = list(lower = model_null, upper = model_full)` Аргумент `direction` позволяет задать направление поиска.

Первый аргумент (`object`) задаёт начальную модель, с которой начинается поиск. Обратите внимание на то, что при разных значениях аргумента `direction` нужно использовать разные начальные модели.

Функция `step` возвращает оптимальную модель.

Итак, задача! C помощью функции `step` найдите оптимальную модель для предсказания `rating` в датасете `attitude`. `Model_full` и `model_null` уже созданы. Сохраните команду с функцией `step` в переменную `ideal_model`.

```{r}
model_full <- lm(rating ~ ., data = attitude)
model_null <- lm(rating ~ 1, data = attitude)

# answer:
ideal_model <- step(model_full, direction = 'backward', scope = list(lower = model_null, upper = model_full))
```

Сравните полную модель из предыдущего степа и оптимальную модель с помощью функции anova. Введите получившееся F-значение.

Разделителем дробной и целой части в ответе должна быть запятая.

```{r}
model <- anova(ideal_model, model_full)
print(model)
ans <- model$F[2]
print('-----')
print(ans)
```

Напоследок потренируемся в эффективном написании формул. В этой задаче будем работать со встроенным датасетом `LifeCycleSavings`. Попытаемся предсказать значение `sr` на основе всех остальных переменных в этом датасете. Вспомните способы сокращения формул и напишите команду, которая создаёт линейную регрессию с главными эффектами и всеми возможными взаимодействиями второго уровня. Сохраните модель в переменную model.

```{r}
model <- lm(sr~.^2, data=LifeCycleSavings)
```

В переменной my_vector хранится вектор значений.

`my_vector <- c(0.027, 0.079, 0.307, 0.098, 0.021, 0.091, 0.322, 0.211, 0.069, 0.261, 0.241, 0.166, 0.283, 0.041, 0.369, 0.167, 0.001, 0.053, 0.262, 0.033, 0.457, 0.166, 0.344, 0.139, 0.162, 0.152, 0.107, 0.255, 0.037, 0.005, 0.042, 0.220, 0.283, 0.050, 0.194, 0.018, 0.291, 0.037, 0.085, 0.004, 0.265, 0.218, 0.071, 0.213, 0.232, 0.024, 0.049, 0.431, 0.061, 0.523)`

Какое преобразование позволяет сделать его распределение нормальным (согласно `shapiro.test`)?

```{r}
my_vector <- c(0.027, 0.079, 0.307, 0.098, 0.021, 0.091, 0.322, 0.211, 0.069, 0.261, 0.241, 0.166, 0.283, 0.041, 0.369, 0.167, 0.001, 0.053, 0.262, 0.033, 0.457, 0.166, 0.344, 0.139, 0.162, 0.152, 0.107, 0.255, 0.037, 0.005, 0.042, 0.220, 0.283, 0.050, 0.194, 0.018, 0.291, 0.037, 0.085, 0.004, 0.265, 0.218, 0.071, 0.213, 0.232, 0.024, 0.049, 0.431, 0.061, 0.523)

ggplot()+
  aes(my_vector)+
  geom_histogram()

print(shapiro.test(my_vector))
print(shapiro.test(log(my_vector)))
print(shapiro.test(sqrt(my_vector)))
print(shapiro.test(1/(my_vector)))
```

## 3.4 Model diagnostics

Функция `scale()` позволяет совершить стандартизацию вектора, то есть делает его среднее значение равным нулю, а стандартное отклонение - единице (Z-преобразование).

Стандартизованный коэффициент регрессии ($\beta$) можно получить, если предикторы и зависимая переменная стандартизованы.

Напишите функцию, которая на вход получает dataframe с двумя количественными переменными, а возвращает стандартизованные коэффициенты для регрессионной модели, в которой первая переменная датафрейма выступает в качестве зависимой, а вторая в качестве независимой.

Примеры работы функции.

> beta.coef(mtcars[,c(1,3)])  

> -7.036582e-17 -8.475514e-01  

> beta.coef(swiss[,c(1,4)])  

> 3.603749e-16 -6.637889e-01  

```{r}
beta.coef <- function(x){
  x <- as.data.frame(scale(x))
  model <- lm(x[,1]~x[,2], data=x)
  return(model$coefficients)
}

beta.coef(mtcars[,c(1,3)])
```

Напишите функцию `normality.test`, которая получает на вход `dataframe` с количественными переменными, проверяет распределения каждой переменной на нормальность с помощью функции `shapiro.test`. Функция должна возвращать вектор с значениями `p - value`, полученного в результате проверки на нормальность каждой переменной. Названия элементов вектора должны совпадать с названиями переменных. 

Пример работы функции:


> normality.test(mtcars[,1:6])  

>         mpg          cyl         disp           hp         drat           wt    
>1.228814e-01 6.058338e-06 2.080657e-02 4.880824e-02 1.100608e-01 9.265499e-02    


> normality.test(iris[,-5])   

>Sepal.Length  Sepal.Width Petal.Length  Petal.Width    
>1.018116e-02 1.011543e-01 7.412263e-10 1.680465e-08    

Опять же, обратите внимание функция должна работать корректно с различным количеством переменных и в независимости от их названий.

Подсказка. Как задать имена элементов вектора:

> my_vector <- c(1, 2, 3, 4)  

> names(my_vector) <- c("A", "B", "C", "D")  

> my_vector  

> A B C D   
> 1 2 3 4   

* мы подробнее поговорим о функциях семейства `apply` в следующем курсе - Advanced R, но вы можете изучить справку о `apply` и `sapply`. Для решения данной задачи, эти функции могут пригодиться

```{r}
# ?sapply
normality.test <- function(x){
  ans <- sapply(x, FUN = shapiro.test, USE.NAMES = TRUE)['p.value',]
  names(ans) <- colnames(x)
  return(unlist(ans))
}

normality.test(mtcars[,1:6])
```

## 3.5 Model diagnostics. Continuous


